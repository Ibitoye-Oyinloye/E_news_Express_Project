{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibitoye-Oyinloye/E_news_Express_Project/blob/main/E_news_Express_Project(Ibitoye).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6l6pBWuh6G5"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "An online news portal aims to expand its business by acquiring new subscribers. Every visitor to the website takes certain actions based on their interest. The company plans to analyze these interests and wants to determine whether a new feature will be effective or not. Companies often analyze users' responses to two variants of a product to decide which of the two variants is more effective. This experimental technique is known as a/b testing that is used to determine whether a new feature attracts users based on a chosen metric.\n",
        "\n",
        "Suppose you are hired as a Data Scientist in E-news Express. The design team of the company has created a new landing page. You have been assigned the task to decide whether the new landing page is more effective to gather new subscribers. Suppose you randomly selected 100 users and divided them equally into two groups. The old landing page is served to the first group (control group) and the new landing page is served to the second group (treatment group). Various data about the customers in both groups are collected in 'abtest.csv'. Perform the statistical analysis to answer the following questions using the collected data.\n",
        "\n",
        "1. Explore the dataset and extract insights using Exploratory Data Analysis.\n",
        "\n",
        "2. Do the users spend more time on the new landing page than the existing landing page?\n",
        "\n",
        "3. Is the conversion rate (the proportion of users who visit the landing page and get converted) for the new page greater than the conversion rate for the old page?\n",
        "\n",
        "4. Does the converted status depend on the preferred language? [Hint: Create a contingency table using the pandas.crosstab() function]\n",
        "\n",
        "5. Is the time spent on the new page same for the different language users?\n",
        "\n",
        "\n",
        "*Consider a significance level of 0.05 for all tests.\n",
        "\n",
        "The  idea  behind  answering  these  questions  is  to  decide  whether  the  new  page  is  effective  enough  to  gather  new subscribers for the news portal. We will perform the statistical analysis on the collected data to make the business decision.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNj01H3ziOXl"
      },
      "source": [
        "# Data Dictionary\n",
        "\n",
        "1. user_id - This represents the user ID of the person visiting the website.\n",
        "\n",
        "2. group - This represents whether the user belongs to the first group (control) or the second group (treatment).\n",
        "\n",
        "3. landing_page - This represents whether the landing page is new or old.\n",
        "\n",
        "4. time_spent_on_the_page - This represents the time (in minutes) spent by the user on the landing page.\n",
        "\n",
        "5. converted - This represents whether the user gets converted to a subscriber of the news portal or not.\n",
        "\n",
        "6. language_preferred - This represents the language chosen by the user to view the landing page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQoA4LIAi4R4"
      },
      "source": [
        "## Import all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viyP4WH8iD-9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "import io\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEXZmX4d8t-7",
        "outputId": "e6599504-475b-4af1-a4d5-ce7519dd92c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-df161a86eec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abtest.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'abtest.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('abtest.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrx-Xg4vi7Y4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-uPc2GhjUxm"
      },
      "outputs": [],
      "source": [
        "# Read file directly from mounted link\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/abtest (1).csv')\n",
        "df.sample(n=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ-GYADOljqI"
      },
      "source": [
        "### Understand the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abzFkFyrkrK3"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsjO48E5lmom"
      },
      "source": [
        "- The data is 100 rows by 6 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHmHMf3MllVB"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hEIStbvlu9r"
      },
      "source": [
        "There are total 100 non-null observations in each of the columns.\n",
        "\n",
        "There are 6 columns named 'user_id', 'group', 'landing_page', 'time_spent_on_the_page', 'converted', 'language_preferred' whose data types are int64, object, object, float64, object, object respectively.\n",
        "\n",
        "'group', 'landing_page', 'converted', and 'language_preferred' are objects, we can change them to categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3tiWAOtmPav"
      },
      "source": [
        "### Convert Objects to Categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNjcNPFqltzf"
      },
      "outputs": [],
      "source": [
        "df['group'] = df['group'].astype('category')\n",
        "df['landing_page'] = df['landing_page'].astype('category')\n",
        "df['converted'] = df['converted'].astype('category')\n",
        "df['language_preferred'] = df['language_preferred'].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpjJPXhEmbEM"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c03Jtwelmy--"
      },
      "source": [
        "## MIssing Values Check and Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h5PVddnmcwR"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaRVe_ihm542"
      },
      "source": [
        "- There are no missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IfKE1wtm3Gk"
      },
      "outputs": [],
      "source": [
        "df.duplicated().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XocO__j3nFBR"
      },
      "source": [
        "- There are no duplictes in the variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DNfUzIcnfoO"
      },
      "source": [
        "## Statistical Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3N3O1Idm_FJ"
      },
      "outputs": [],
      "source": [
        "# let's view the statistical summary of the non-numerical columns in the data\n",
        "df.describe(exclude=np.number).T.style.highlight_max(color=\"yellow\", axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeHOkLYhnlAB"
      },
      "outputs": [],
      "source": [
        "# let's view the statistical summary of the numerical columns in the data\n",
        "df.describe(include=np.number).T.style.highlight_max(color=\"yellow\", axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvywv0iFnslp"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH8EXlvTpiLh"
      },
      "source": [
        "- There are 100 unique users.\n",
        "- There are 2 unique groups - control and treatment. Each group consists of 50 users.\n",
        "- There are 2 landing_pages - new and old.\n",
        "- Overall, 54 users get converted and 46 users do not get converted after visiting the landing page.\n",
        "- French is the most preferred language\n",
        "- Time spent on page averagly is 5.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEqy5WmOslsa"
      },
      "outputs": [],
      "source": [
        "# We drop UserId as it is not relevant to help us draw inferences on the population\n",
        "df.drop(['user_id'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhwN-B8zsyop"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpcwXHXp8L7"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKRaEoBGn_lL"
      },
      "outputs": [],
      "source": [
        "def histogram_boxplot(feature, figsize=(15,10), bins = None):\n",
        "    \"\"\" Boxplot and histogram combined\n",
        "    feature: 1-d feature array\n",
        "    figsize: size of fig (default (9,8))\n",
        "    bins: number of bins (default None / auto)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(nrows = 2, # Number of rows of the subplot grid= 2\n",
        "                                           sharex = True, # x-axis will be shared among all subplots\n",
        "                                           gridspec_kw = {\"height_ratios\": (.25, .75)}, \n",
        "                                           figsize = figsize \n",
        "                                           ) # creating the 2 subplots\n",
        "    sns.boxplot(feature, ax=ax_box2, showmeans=True, color='Lightgreen') # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.distplot(feature, kde=F, ax=ax_hist2, bins=bins,palette=\"winter\") if bins else sns.distplot(feature, kde=False, ax=ax_hist2) # For histogram\n",
        "    ax_hist2.axvline(np.mean(feature), color='green', linestyle='--') # Add mean to the histogram\n",
        "    ax_hist2.axvline(np.median(feature), color='black', linestyle='-') # Add median to the histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu7R1f44s8FP"
      },
      "source": [
        "### Observations on Time Spent on Page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkBsrTbNqRQE"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df[\"time_spent_on_the_page\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeldRZU1rrPw"
      },
      "source": [
        "- The distribution of time spent on the page is normally distributed There are no outliers in this variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA8WDgy7rhTf"
      },
      "outputs": [],
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(data=data, x=feature, palette=\"Paired\", order=data[feature].value_counts().index[:n].sort_values())\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(100 * p.get_height() / total)  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()      # height of the plot\n",
        "\n",
        "        ax.annotate(label, (x, y), ha=\"center\", va=\"center\", size=12, xytext=(0, 5), textcoords=\"offset points\")  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKW4e2_qsBWU"
      },
      "source": [
        "### Observations on Landing page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHtSL-Zr272"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df,'landing_page',perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0gl5NQcsKOk"
      },
      "source": [
        "- The distribution of observations across the two landing pages are same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAYEWMjesREU"
      },
      "source": [
        "### Observation on group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzgP9nVxsGFh"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df,'group',perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_J1hzwCscox"
      },
      "source": [
        "- The distribution of observations across groups are the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ridob7ZztDRL"
      },
      "source": [
        "### Observations on language_preferred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK2ykBoJsXZI"
      },
      "outputs": [],
      "source": [
        "\n",
        "labeled_barplot(df,'language_preferred',perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHTK17lAtLP0"
      },
      "source": [
        "- English is the least language_preferred while Spanish and French have equal preference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TygOa5eMtXyJ"
      },
      "source": [
        "## Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Og66V8th_b"
      },
      "source": [
        "### Time Spent on Page Vs Converted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdftO7NStJy8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.histplot(data = df, x = 'time_spent_on_the_page', hue = 'converted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moHJP0asq0Sd"
      },
      "source": [
        "- Customers who spent 6 minutes and above got converted.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg8HvrDKp31H"
      },
      "source": [
        "##  Does the converted status depend on the preferred language?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlDQj9cpuJcy"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(df[\"converted\"],hue=df[\"language_preferred\"],palette='viridis')\n",
        "plt.legend(bbox_to_anchor=(1.00, 1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDdKNjy7p9I7"
      },
      "source": [
        "- Customers who converted prefer English Language\n",
        "- Customers who did not convert prefer French more than the other languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2IC0ARcrULw"
      },
      "source": [
        "## Is the mean time spent on the new page same for the different language users?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh9_7IlssEfV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(df[\"language_preferred\"],df[\"time_spent_on_the_page\"],palette=\"viridis\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5IFCO_nstE_"
      },
      "source": [
        "- Users spent slightly more time on French as compared to English\n",
        "- Spanish speaking customers spent less time on the page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UzHmBc3tb_l"
      },
      "source": [
        "## Do the users spend more time on the new landing page than the old landing page?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAF5WvH4sUOO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(df[\"landing_page\"],df[\"time_spent_on_the_page\"],palette=\"viridis\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJSbFPjftwVF"
      },
      "source": [
        "- people spent more times on the new page than the old age"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xotyDl5viml"
      },
      "source": [
        "## Step 1: Define the null and alternate hypotheses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxs70xWSuNw2"
      },
      "source": [
        "$H_0:$ The mean time spent by the users on the new page is equal to the mean time spent by the users on the old page.\n",
        "\n",
        "$H_a:$ The mean time spent by the users on the new page is greater than the mean time spent by the users on the old page.\n",
        "\n",
        "Let $\\mu_1$ and $\\mu_2$ be the mean time spent by the users on the new and old page respectively.\n",
        "\n",
        "Mathematically, the above formulated hypotheses can be written as:\n",
        "\n",
        "$H_0: \\mu_1 = \\mu_2$\n",
        "\n",
        "$H_a: \\mu_1 > \\mu_2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUmau5zZvvOO"
      },
      "source": [
        "## Step 2: Select Appropriate test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHtBsTnWxsW9"
      },
      "source": [
        "- This is a one-tailed test concerning two population means from two independent populations. As the population standard deviations are unknown, the two sample independent t-test will be the appropriate test for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqZsidttyZUr"
      },
      "source": [
        "## Step 3: Collect the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gDVGQr2toEP"
      },
      "outputs": [],
      "source": [
        "time_spent_new = df[df['landing_page'] == 'new']['time_spent_on_the_page']\n",
        "time_spent_old = df[df['landing_page'] == 'old']['time_spent_on_the_page']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Terd3EoyDZ2"
      },
      "outputs": [],
      "source": [
        "print('The sample standard deviation of the time spent on the new page is:', round(time_spent_new.std(),2))\n",
        "print('The sample standard deviation of the time spent on the new page is:', round(time_spent_old.std(),2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUTZGEsEyUrZ"
      },
      "source": [
        "## Step 4: Calculate the p-value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6sldzfsyFKf"
      },
      "outputs": [],
      "source": [
        "# import the required function\n",
        "from scipy.stats import ttest_ind\n",
        "# find the p-value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOc200Zay3NX"
      },
      "outputs": [],
      "source": [
        "test_stat, p_value = ttest_ind(time_spent_new, time_spent_old, equal_var = False, alternative = 'greater')\n",
        "print('The p-value is', p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umu6IAYm8t_h"
      },
      "source": [
        "## Step 5: Compare the p-value with $\\alpha$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGW6t1-q8t_h"
      },
      "source": [
        "Since the p-value is less than the 5% significance level, we reject the null hypothesis. Hence, we have enough statistical evidence to say that the mean time spent by the users on the new page is greater than the mean time spent by the users on the old page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi92F5UW8t_h"
      },
      "source": [
        "## 3. Is the conversion rate (the proportion of users who visit the landing page and get converted) for the new page greater than the conversion rate for the old page?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV9psdhS8t_i"
      },
      "source": [
        "$H_0:$ The conversion rate for the new page is equal to the conversion rate for the old page.\n",
        "\n",
        "$H_a:$ The conversion rate for the new page is greater than the conversion rate for the old page.\n",
        "\n",
        "Let $p_1$ and $p_2$ be the conversion rate for the new and old page respectively.\n",
        "\n",
        "Mathematically, the above formulated hypotheses can be written as:\n",
        "\n",
        "$H_0: p_1 = p_2$\n",
        "\n",
        "$H_a: p_1 > p_2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hUM8OiS8t_i"
      },
      "source": [
        "This is a one-tailed test concerning two population proportions from two independent populations. Hence, the two proportion z-test will be the appropriate test for this problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws-NFlOD8t_i"
      },
      "source": [
        "## Collect and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F75OnXWy8t_i"
      },
      "outputs": [],
      "source": [
        "new_converted = df[df['group'] == 'treatment']['converted'].value_counts()['yes']\n",
        "old_converted = df[df['group'] == 'control']['converted'].value_counts()['yes']\n",
        "print('The numbers of converted users for the new and old pages are {0} and {1} respectively'.format(new_converted, old_converted))\n",
        "n_control = df.group.value_counts()['control'] # number of users in the control group\n",
        "n_treatment = df.group.value_counts()['treatment'] #number of users in the treatment group\n",
        "print('The numbers of users served the new and old pages are {0} and {1} respectively'.format(n_control, n_treatment ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reZCwKGN8t_j"
      },
      "source": [
        "### Calculate the Probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikiuSi8W8t_j"
      },
      "outputs": [],
      "source": [
        "# import the required function\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# find the p-value\n",
        "test_stat, p_value = proportions_ztest([new_converted, old_converted] , [n_treatment, n_control], alternative = 'larger')\n",
        "print('The p-value is', p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcSZTddm8t_k"
      },
      "source": [
        "Since the p-value is less than the 5% significance level, we reject the null hypothesis. Hence, we have enough statistical evidence to say that the conversion rate for the new page is greater than the conversion rate for the old page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TujyWijX8t_k"
      },
      "source": [
        "## 4. Is the conversion and preferred language are independent or related?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WFJWWce8t_k"
      },
      "source": [
        "$H_0:$ The converted status is independent of the preferred language.\n",
        "\n",
        "$H_a:$ The converted status is not independent of the preferred language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwJyt5xn8t_k"
      },
      "source": [
        "This is a problem of Chi-square test of independence, concerning the two independent categorical variables, converted status and preferred language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSErmL8I8t_l"
      },
      "outputs": [],
      "source": [
        "# create the contingency table showing the distribution of two categorical variables\n",
        "contingency_table = pd.crosstab(df['converted'], df['language_preferred'])\n",
        "contingency_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Ifj6q88t_l"
      },
      "outputs": [],
      "source": [
        "#import the required function\n",
        "from scipy.stats import chi2_contingency\n",
        "# use chi2_contingency() to find the p-value\n",
        "chi2, p_value, dof, exp_freq = chi2_contingency(contingency_table)\n",
        "# print the p-value\n",
        "print('The p-value is', p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJPvgU-a8t_m"
      },
      "source": [
        "Since the p-value is greater than the 5% significance level, we fail to reject the null hypothesis. Hence, we do not have enough statistical evidence to say that the converted status depends on the preferred language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6WaD5j8t_m"
      },
      "source": [
        "## 5. Is the time spent on the new page same for the different language users?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aSOkdfc8t_m"
      },
      "source": [
        "$H_0:$ The mean times spent on the new page by English, French, and Spanish users are equal.\n",
        "\n",
        "$H_a:$ At least one of the mean times spent on the new page by English, French, and Spanish users is unequal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsa7IIhH8t_m"
      },
      "source": [
        "This is a problem, concerning three population means. One-way ANOVA could be the appropriate test here provided normality and equality of variance assumptions are verified.\n",
        "\n",
        "* For testing of normality, Shapiro-Wilk’s test is applied to the response variable.\n",
        "\n",
        "* For equality of variance, Levene test is applied to the response variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImZMLHMx8t_n"
      },
      "source": [
        "### Shapiro-Wilk’s test\n",
        "\n",
        "We will test the null hypothesis\n",
        "\n",
        ">$H_0:$ Time spent on the new page follows a normal distribution\n",
        "\n",
        "against the alternative hypothesis\n",
        "\n",
        ">$H_a:$ Time spent on the new page does not follow a normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke-q3aUx8t_o"
      },
      "outputs": [],
      "source": [
        "# Checking the mean time spent on the new page for different language users\n",
        "df.groupby(['language_preferred'])['time_spent_on_the_page'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfOR8XeJ8t_o"
      },
      "outputs": [],
      "source": [
        "## Assumption 1: Normality\n",
        "##  import the required function\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "##  find the p-value\n",
        "w, p_value = shapiro(df['time_spent_on_the_page']) \n",
        "print('The p-value is', p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Y-pHye8t_o"
      },
      "source": [
        "Since p-value of the test is very large than the 5% significance level, we fail to reject the null hypothesis that the response follows the normal distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjEIevOA8t_p"
      },
      "source": [
        "### Levene’s test\n",
        "\n",
        "We will test the null hypothesis\n",
        "\n",
        ">$H_0$: All the population variances are equal\n",
        "\n",
        "against the alternative hypothesis\n",
        "\n",
        ">$H_a$: At least one variance is different from the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV2efwgM8t_p"
      },
      "outputs": [],
      "source": [
        "#Assumption 2: Homogeneity of Variance\n",
        "#import the required function\n",
        "from scipy.stats import levene\n",
        "statistic, p_value = levene( df[df['language_preferred']==\"English\"]['time_spent_on_the_page'], \n",
        "                             df[df['language_preferred']==\"French\"]['time_spent_on_the_page'], \n",
        "                             df[df['language_preferred']==\"Spanish\"]['time_spent_on_the_page'])\n",
        "# find the p-value\n",
        "print('The p-value is', p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZlDYX7p8t_p"
      },
      "source": [
        "Since the p-value is large than the 5% significance level, we fail to reject the null hypothesis of homogeneity of variances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qftnWLP8t_q"
      },
      "outputs": [],
      "source": [
        "time_spent_English = df[df['language_preferred']==\"English\"]['time_spent_on_the_page']\n",
        "time_spent_French = df[df['language_preferred']==\"French\"]['time_spent_on_the_page']\n",
        "time_spent_Spanish = df[df['language_preferred']==\"Spanish\"]['time_spent_on_the_page']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOG6OxDv8t_q"
      },
      "outputs": [],
      "source": [
        "# import the required function\n",
        "from scipy.stats import f_oneway\n",
        "# find the p-value\n",
        "test_stat, p_value = f_oneway(time_spent_English, time_spent_French, time_spent_Spanish)\n",
        "# print the p-value\n",
        "print('The p-value is', p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoGHaIx98t_q"
      },
      "source": [
        "As the p-value 0.8665610536012648 is greater than the level of significance, we fail to reject the null hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtThv0jj8t_r"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "-Users spend more time on the new landing page than the old landing page\n",
        "- More time is spent on new landing page than on the old landing page.\n",
        "- More time is spent on English language in the new landing page as compared to French and Spanish\n",
        "- Spanish language is the most prefered as more time is spent in the old landing page.\n",
        "- Less English language is prefered in the old landing page\n",
        "- Treatment group has a higher median value on time spent on the pages than control group.\n",
        "- Control group has no outliers and tratment group has outliers below the minimum and above the minimum time spent on the page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRnB_3hV8t_r"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "E_news_Express_Project(Ibitoye).ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}